This is the **"Echo Engine" Pipeline**.

There is no single off-the-shelf app that does this specific "Philosophy Debate" format automatically. You have to build it.

Below is the **Architecture** and the **Python Code** (The "App") that you can run on your computer.

### **The Pipeline Architecture**

1. **The Brain (Scripting):** You feed the Thesis to **GPT-4**. It outputs a structured script (JSON).
2. **The Mouth (Voice):** The script is sent to **ElevenLabs**, which generates distinct audio files for Socrates, Nietzsche, and Spinoza.
3. **The Face (Visuals):** The code pulls static avatars (or stock video) for each character.
4. **The Glue (Editing):** **MoviePy** stitches the audio and visuals together, adds the "Lo-Fi" background beat, and renders the MP4.

---

### **The App (Python Code)**

You will need an API Key from **OpenAI** (for the script) and **ElevenLabs** (for the voices).

Save this code as `echo_engine.py`.

```python
import os
import json
from openai import OpenAI
from moviepy.editor import *
import requests

# --- CONFIGURATION ---
OPENAI_API_KEY = "YOUR_OPENAI_KEY"
ELEVENLABS_API_KEY = "YOUR_ELEVENLABS_KEY"

# Character Voice IDs (From ElevenLabs)
VOICES = {
    "Socrates": "voice_id_for_calm_british_male",
    "Nietzsche": "voice_id_for_intense_german_male",
    "Spinoza": "voice_id_for_soft_dutch_male"
}

client = OpenAI(api_key=OPENAI_API_KEY)

# --- STEP 1: THE WRITER ---
def generate_script(topic):
    print(f"writing script for: {topic}...")
    
    prompt = f"""
    Write a 1-minute podcast debate about: "{topic}".
    Characters: 
    1. Socrates (Host, curious)
    2. Nietzsche (Cynic, aggressive)
    3. Spinoza (Rational, calm)
    
    Output strictly in this JSON format:
    [
      {{"speaker": "Socrates", "text": "..."}},
      {{"speaker": "Nietzsche", "text": "..."}}
    ]
    """
    
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "system", "content": "You are a screenwriter."},
                  {"role": "user", "content": prompt}]
    )
    
    return json.loads(response.choices[0].message.content)

# --- STEP 2: THE ACTOR ---
def generate_audio(script):
    print("Generating voices...")
    audio_files = []
    
    headers = {
        "xi-api-key": ELEVENLABS_API_KEY,
        "Content-Type": "application/json"
    }
    
    for i, line in enumerate(script):
        speaker = line["speaker"]
        text = line["text"]
        
        # Call ElevenLabs API
        url = f"https://api.elevenlabs.io/v1/text-to-speech/{VOICES[speaker]}"
        payload = {
            "text": text,
            "model_id": "eleven_monolingual_v1",
            "voice_settings": {"stability": 0.5, "similarity_boost": 0.75}
        }
        
        response = requests.post(url, json=payload, headers=headers)
        
        filename = f"temp_{i}_{speaker}.mp3"
        with open(filename, "wb") as f:
            f.write(response.content)
        
        audio_files.append({"file": filename, "speaker": speaker})
        
    return audio_files

# --- STEP 3: THE EDITOR ---
def assemble_video(audio_data):
    print("Editing video...")
    clips = []
    
    # Load Character Images (You need socrates.jpg, nietzsche.jpg in folder)
    avatars = {
        "Socrates": "assets/socrates.jpg",
        "Nietzsche": "assets/nietzsche.jpg",
        "Spinoza": "assets/spinoza.jpg"
    }
    
    for item in audio_data:
        # Create Audio Clip
        audio = AudioFileClip(item["file"])
        
        # Create Image Clip (Static image of the speaker)
        # Note: In V2, we can replace this with AI Video clips
        video = ImageClip(avatars[item["speaker"]]).set_duration(audio.duration)
        video = video.set_audio(audio)
        
        clips.append(video)
        
    # Concatenate all clips
    final_video = concatenate_videoclips(clips)
    
    # Write Output
    final_video.write_videofile("output/final_debate.mp4", fps=24)
    
    # Cleanup Temp Files
    for item in audio_data:
        os.remove(item["file"])

# --- MAIN EXECUTION ---
if __name__ == "__main__":
    topic = "Does Security require Walls or Integration?"
    
    # 1. Write
    script_json = generate_script(topic)
    
    # 2. Speak
    audio_assets = generate_audio(script_json)
    
    # 3. Edit
    assemble_video(audio_assets)
    
    print("Done! Check output/final_debate.mp4")

```

### **How to Run This**

1. **Install Python:** Download Python from python.org.
2. **Install Libraries:** Open your terminal and type:
`pip install openai moviepy requests`
3. **Get Images:** Put 3 images (`socrates.jpg`, `nietzsche.jpg`, `spinoza.jpg`) in a folder named `assets`.
4. **Run It:** Type `python echo_engine.py`.

### **The Upgrade (V2)**

The code above makes a "Static Image" video (like a visual podcast).
To get the **Glitch/Video** style:

* Replace `ImageClip(avatars[...])` with a function that pulls a random stock video from a local "glitch_footage" folder based on the speaker's mood.

This script *is* your automated factory. It turns a sentence into a produced debate in about 60 seconds.